"""
Servicio de Generaci√≥n de Embeddings usando Hugging Face Inference API
=======================================================================

SOLUCI√ìN PARA LIMITACIONES DE RAM:
En lugar de cargar el modelo MegaDescriptor localmente (1.5GB de RAM),
este servicio usa la Inference API de Hugging Face que ya tiene el modelo
cargado en sus servidores.

VENTAJAS:
- ‚úÖ NO requiere 1.5GB de RAM en tu servidor
- ‚úÖ GRATIS (rate limit: 1000 requests/hora)
- ‚úÖ Funciona en servidores con solo 512MB RAM
- ‚úÖ Mismo modelo MegaDescriptor que usar√≠as localmente
- ‚úÖ Mismo formato de embeddings (compatible con tu c√≥digo existente)

DESVENTAJAS:
- Depende de conexi√≥n a internet
- Rate limit de 1000 requests/hora (suficiente para demo/tesis)
"""

import io
import asyncio
import os
from typing import Optional
import numpy as np
from PIL import Image
import httpx  # Cliente HTTP as√≠ncrono

# Configuraci√≥n de Hugging Face API
HF_API_URL = "https://api-inference.huggingface.co/models/BVRA/MegaDescriptor-L-384"
HF_API_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN", "")  # Token opcional pero recomendado

# Headers para la API
HEADERS = {}
if HF_API_TOKEN:
    HEADERS["Authorization"] = f"Bearer {HF_API_TOKEN}"

# Dimensi√≥n del embedding de MegaDescriptor-L-384
EMBEDDING_DIM = 1536

# Cliente HTTP reutilizable
_http_client = None

# Sem√°foro para limitar concurrencia (m√°ximo 3 requests simult√°neos)
_inference_semaphore = None


def _get_http_client():
    """Obtiene o crea el cliente HTTP."""
    global _http_client
    if _http_client is None:
        _http_client = httpx.AsyncClient(timeout=30.0)
    return _http_client


def _get_semaphore():
    """Obtiene o crea el sem√°foro (lazy initialization para evitar problemas con event loop)."""
    global _inference_semaphore
    if _inference_semaphore is None:
        _inference_semaphore = asyncio.Semaphore(3)
    return _inference_semaphore


async def generate_embedding_from_bytes(image_bytes: bytes) -> Optional[np.ndarray]:
    """
    Genera un embedding de una imagen usando Hugging Face Inference API.
    
    Args:
        image_bytes: Bytes de la imagen (JPEG, PNG, etc.)
        
    Returns:
        numpy array con el embedding de 1536 dimensiones, o None si falla
    """
    try:
        # Verificar que la imagen sea v√°lida antes de enviarla
        try:
            img = Image.open(io.BytesIO(image_bytes))
            img.verify()
        except Exception as e:
            print(f"‚ùå Imagen inv√°lida: {e}")
            return None
        
        # Reabrir la imagen despu√©s de verify() (verify() cierra el archivo)
        img = Image.open(io.BytesIO(image_bytes))
        
        # Convertir a RGB si es necesario
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Redimensionar a 384x384 (tama√±o esperado por MegaDescriptor)
        img = img.resize((384, 384), Image.Resampling.LANCZOS)
        
        # Guardar imagen procesada en bytes
        img_io = io.BytesIO()
        img.save(img_io, format='JPEG', quality=95)
        processed_bytes = img_io.getvalue()
        
        # Llamar a la API de Hugging Face con sem√°foro para limitar concurrencia
        async with _get_semaphore():
            client = _get_http_client()
            
            print(f"üîÑ Enviando imagen a Hugging Face API...")
            
            response = await client.post(
                HF_API_URL,
                headers=HEADERS,
                content=processed_bytes,
                timeout=30.0
            )
            
            # Verificar respuesta
            if response.status_code == 503:
                # Modelo carg√°ndose en el servidor de HF
                print("‚è≥ Modelo carg√°ndose en Hugging Face, reintentando en 20s...")
                await asyncio.sleep(20)
                
                # Reintentar
                response = await client.post(
                    HF_API_URL,
                    headers=HEADERS,
                    content=processed_bytes,
                    timeout=30.0
                )
            
            if response.status_code != 200:
                print(f"‚ùå Error en Hugging Face API: {response.status_code}")
                print(f"   Respuesta: {response.text}")
                return None
            
            # La API devuelve el embedding como lista de floats
            embedding = response.json()
            
            # Convertir a numpy array
            embedding_array = np.array(embedding, dtype=np.float32)
            
            # Normalizar el embedding (L2 normalization)
            norm = np.linalg.norm(embedding_array)
            if norm > 0:
                embedding_array = embedding_array / norm
            
            print(f"‚úÖ Embedding generado: dimensi√≥n {len(embedding_array)}")
            
            return embedding_array
            
    except Exception as e:
        print(f"‚ùå Error generando embedding: {e}")
        import traceback
        traceback.print_exc()
        return None


async def generate_embeddings_batch(images_bytes: list[bytes]) -> list[Optional[np.ndarray]]:
    """
    Genera embeddings para m√∫ltiples im√°genes en paralelo.
    
    Args:
        images_bytes: Lista de bytes de im√°genes
        
    Returns:
        Lista de embeddings (numpy arrays) o None para las que fallen
    """
    if not images_bytes:
        return []
    
    print(f"üîÑ Generando {len(images_bytes)} embeddings en batch...")
    
    # Generar embeddings en paralelo
    tasks = [generate_embedding_from_bytes(img_bytes) for img_bytes in images_bytes]
    embeddings = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Convertir excepciones a None
    result = []
    for emb in embeddings:
        if isinstance(emb, Exception):
            print(f"‚ùå Error en batch: {emb}")
            result.append(None)
        else:
            result.append(emb)
    
    successful = sum(1 for e in result if e is not None)
    print(f"‚úÖ Batch completado: {successful}/{len(images_bytes)} exitosos")
    
    return result


def get_embedding_dim() -> int:
    """Retorna la dimensi√≥n del embedding."""
    return EMBEDDING_DIM


async def cleanup():
    """Limpia recursos al cerrar la aplicaci√≥n."""
    global _http_client
    if _http_client:
        await _http_client.aclose()
        _http_client = None
